{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df_2 = pd.read_csv('data2.csv')\n",
    "df_3 = pd.read_csv('data3.csv')\n",
    "\n",
    "# print(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>540088.14</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2079.90</td>\n",
       "      <td>15106.97</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1788.39</td>\n",
       "      <td>291.51</td>\n",
       "      <td>1971.01</td>\n",
       "      <td>84.40</td>\n",
       "      <td>98077.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>-122.21</td>\n",
       "      <td>1986.55</td>\n",
       "      <td>12768.46</td>\n",
       "      <td>2014.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>367127.20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>918.44</td>\n",
       "      <td>41420.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.18</td>\n",
       "      <td>828.09</td>\n",
       "      <td>442.58</td>\n",
       "      <td>29.37</td>\n",
       "      <td>401.68</td>\n",
       "      <td>53.51</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>685.39</td>\n",
       "      <td>27304.18</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>520.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98001.00</td>\n",
       "      <td>47.16</td>\n",
       "      <td>-122.52</td>\n",
       "      <td>399.00</td>\n",
       "      <td>651.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>321950.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1427.00</td>\n",
       "      <td>5040.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1190.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1951.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98033.00</td>\n",
       "      <td>47.47</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>5100.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>450000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1910.00</td>\n",
       "      <td>7618.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1560.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1975.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98065.00</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>7620.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>645000.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550.00</td>\n",
       "      <td>10688.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2210.00</td>\n",
       "      <td>560.00</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98118.00</td>\n",
       "      <td>47.68</td>\n",
       "      <td>-122.12</td>\n",
       "      <td>2360.00</td>\n",
       "      <td>10083.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7700000.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>13540.00</td>\n",
       "      <td>1651359.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9410.00</td>\n",
       "      <td>4820.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>98199.00</td>\n",
       "      <td>47.78</td>\n",
       "      <td>-121.31</td>\n",
       "      <td>6210.00</td>\n",
       "      <td>871200.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living   sqft_lot   floors  \\\n",
       "count   21613.00  21613.00   21613.00     21613.00   21613.00 21613.00   \n",
       "mean   540088.14      3.37       2.11      2079.90   15106.97     1.49   \n",
       "std    367127.20      0.93       0.77       918.44   41420.51     0.54   \n",
       "min     75000.00      0.00       0.00       290.00     520.00     1.00   \n",
       "25%    321950.00      3.00       1.75      1427.00    5040.00     1.00   \n",
       "50%    450000.00      3.00       2.25      1910.00    7618.00     1.50   \n",
       "75%    645000.00      4.00       2.50      2550.00   10688.00     2.00   \n",
       "max   7700000.00     33.00       8.00     13540.00 1651359.00     3.50   \n",
       "\n",
       "       waterfront     view  condition    grade  sqft_above  sqft_basement  \\\n",
       "count    21613.00 21613.00   21613.00 21613.00    21613.00       21613.00   \n",
       "mean         0.01     0.23       3.41     7.66     1788.39         291.51   \n",
       "std          0.09     0.77       0.65     1.18      828.09         442.58   \n",
       "min          0.00     0.00       1.00     1.00      290.00           0.00   \n",
       "25%          0.00     0.00       3.00     7.00     1190.00           0.00   \n",
       "50%          0.00     0.00       3.00     7.00     1560.00           0.00   \n",
       "75%          0.00     0.00       4.00     8.00     2210.00         560.00   \n",
       "max          1.00     4.00       5.00    13.00     9410.00        4820.00   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "count  21613.00      21613.00 21613.00 21613.00 21613.00       21613.00   \n",
       "mean    1971.01         84.40 98077.94    47.56  -122.21        1986.55   \n",
       "std       29.37        401.68    53.51     0.14     0.14         685.39   \n",
       "min     1900.00          0.00 98001.00    47.16  -122.52         399.00   \n",
       "25%     1951.00          0.00 98033.00    47.47  -122.33        1490.00   \n",
       "50%     1975.00          0.00 98065.00    47.57  -122.23        1840.00   \n",
       "75%     1997.00          0.00 98118.00    47.68  -122.12        2360.00   \n",
       "max     2015.00       2015.00 98199.00    47.78  -121.31        6210.00   \n",
       "\n",
       "       sqft_lot15     year  \n",
       "count    21613.00 21613.00  \n",
       "mean     12768.46  2014.32  \n",
       "std      27304.18     0.47  \n",
       "min        651.00  2014.00  \n",
       "25%       5100.00  2014.00  \n",
       "50%       7620.00  2014.00  \n",
       "75%      10083.00  2015.00  \n",
       "max     871200.00  2015.00  "
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor to original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25517751417256285, 0.4266688773262922, 0.4905486214094186, 0.5131981603678757, 0.5217036549637721, 0.5349943963318078, 0.5309787638767336, 0.5296787982904009, 0.5268025798512307, 0.5271923836537684, 0.5283640726891363, 0.5298267311442775, 0.5298192226317417, 0.5252369229994825, 0.5251530272776073, 0.5217014617544498, 0.5193704459368669, 0.5172809694913204, 0.5161307686484007]\n",
      "The n_neighbors with the highest knn_score is 6\n"
     ]
    }
   ],
   "source": [
    "# X = df.drop(['price'], axis = 1, inplace = False)\n",
    "y = df[[\"price\"]]\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors','waterfront', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'year']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6752)\n",
    "# Search the best n_neighbors value to choose from 1 to 10\n",
    "n_neighbors = []\n",
    "knn_score_list = []\n",
    "for n in range(1,20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn = knn.score(X_test, y_test)\n",
    "    knn_score_list.append(knn)  \n",
    "    n_neighbors.append(n) \n",
    "print(knn_score_list)\n",
    "n_neighbors\n",
    "# find the index of the highest value\n",
    "max_index = np.argmax(knn_score_list)\n",
    "# get the corresponding label\n",
    "max_label = n_neighbors[max_index]\n",
    "print(f\"The n_neighbors with the highest knn_score is {max_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5349943963318078"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=max_label)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocessing**\n",
    "Les données ont besoin d'être transformée avant de pouvoir être utilisées dans un modèle de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.755752668315225"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df['price']\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors','waterfront', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'year']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,random_state=42)\n",
    "\n",
    "# pre-processing de X_train\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "X_train_min_max = minmax.fit_transform(X_train)\n",
    "\n",
    "# Entrainement sur X_train\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=4)\n",
    "trained_model = model.fit(X_train_min_max,y_train)\n",
    "\n",
    "# pre-processing de X_test\n",
    "X_test_min_max = minmax.transform(X_test)\n",
    "\n",
    "# scoring\n",
    "trained_model.score(X_test_min_max,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>540088.14</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2079.90</td>\n",
       "      <td>15106.97</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1788.39</td>\n",
       "      <td>291.51</td>\n",
       "      <td>1971.01</td>\n",
       "      <td>84.40</td>\n",
       "      <td>98077.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>-122.21</td>\n",
       "      <td>1986.55</td>\n",
       "      <td>12768.46</td>\n",
       "      <td>2014.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>367127.20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>918.44</td>\n",
       "      <td>41420.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.18</td>\n",
       "      <td>828.09</td>\n",
       "      <td>442.58</td>\n",
       "      <td>29.37</td>\n",
       "      <td>401.68</td>\n",
       "      <td>53.51</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>685.39</td>\n",
       "      <td>27304.18</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>520.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98001.00</td>\n",
       "      <td>47.16</td>\n",
       "      <td>-122.52</td>\n",
       "      <td>399.00</td>\n",
       "      <td>651.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>321950.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1427.00</td>\n",
       "      <td>5040.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1190.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1951.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98033.00</td>\n",
       "      <td>47.47</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>5100.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>450000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1910.00</td>\n",
       "      <td>7618.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1560.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1975.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98065.00</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>7620.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>645000.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550.00</td>\n",
       "      <td>10688.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2210.00</td>\n",
       "      <td>560.00</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98118.00</td>\n",
       "      <td>47.68</td>\n",
       "      <td>-122.12</td>\n",
       "      <td>2360.00</td>\n",
       "      <td>10083.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7700000.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>13540.00</td>\n",
       "      <td>1651359.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9410.00</td>\n",
       "      <td>4820.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>98199.00</td>\n",
       "      <td>47.78</td>\n",
       "      <td>-121.31</td>\n",
       "      <td>6210.00</td>\n",
       "      <td>871200.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living   sqft_lot   floors  \\\n",
       "count   21613.00  21613.00   21613.00     21613.00   21613.00 21613.00   \n",
       "mean   540088.14      3.37       2.11      2079.90   15106.97     1.49   \n",
       "std    367127.20      0.93       0.77       918.44   41420.51     0.54   \n",
       "min     75000.00      0.00       0.00       290.00     520.00     1.00   \n",
       "25%    321950.00      3.00       1.75      1427.00    5040.00     1.00   \n",
       "50%    450000.00      3.00       2.25      1910.00    7618.00     1.50   \n",
       "75%    645000.00      4.00       2.50      2550.00   10688.00     2.00   \n",
       "max   7700000.00     33.00       8.00     13540.00 1651359.00     3.50   \n",
       "\n",
       "       waterfront     view  condition    grade  sqft_above  sqft_basement  \\\n",
       "count    21613.00 21613.00   21613.00 21613.00    21613.00       21613.00   \n",
       "mean         0.01     0.23       3.41     7.66     1788.39         291.51   \n",
       "std          0.09     0.77       0.65     1.18      828.09         442.58   \n",
       "min          0.00     0.00       1.00     1.00      290.00           0.00   \n",
       "25%          0.00     0.00       3.00     7.00     1190.00           0.00   \n",
       "50%          0.00     0.00       3.00     7.00     1560.00           0.00   \n",
       "75%          0.00     0.00       4.00     8.00     2210.00         560.00   \n",
       "max          1.00     4.00       5.00    13.00     9410.00        4820.00   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "count  21613.00      21613.00 21613.00 21613.00 21613.00       21613.00   \n",
       "mean    1971.01         84.40 98077.94    47.56  -122.21        1986.55   \n",
       "std       29.37        401.68    53.51     0.14     0.14         685.39   \n",
       "min     1900.00          0.00 98001.00    47.16  -122.52         399.00   \n",
       "25%     1951.00          0.00 98033.00    47.47  -122.33        1490.00   \n",
       "50%     1975.00          0.00 98065.00    47.57  -122.23        1840.00   \n",
       "75%     1997.00          0.00 98118.00    47.68  -122.12        2360.00   \n",
       "max     2015.00       2015.00 98199.00    47.78  -121.31        6210.00   \n",
       "\n",
       "       sqft_lot15     year  \n",
       "count    21613.00 21613.00  \n",
       "mean     12768.46  2014.32  \n",
       "std      27304.18     0.47  \n",
       "min        651.00  2014.00  \n",
       "25%       5100.00  2014.00  \n",
       "50%       7620.00  2014.00  \n",
       "75%      10083.00  2015.00  \n",
       "max     871200.00  2015.00  "
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df['price']\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors','waterfront', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'year']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# simple = SimpleImputer(strategy='mean')   # replaces missing data by the mean\n",
    "minmax = MinMaxScaler()\n",
    "knn_4 = KNeighborsRegressor(n_neighbors=max_label)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #  ('simple_imputer', simple ),\n",
    "     ('minmax', minmax),\n",
    "     ('knn', knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7588531476761058"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor to cleaned df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'sqft_living15','sqft_lot15', 'age_house']]\n",
    "#X = X\n",
    "y = df_new[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16871697856057133, 0.3670403483547455, 0.4279398801293275, 0.45747170629106615, 0.4812284109198737, 0.49603041002982007, 0.5013614766341854, 0.5085860528385867, 0.5088119804488029, 0.504518850410655, 0.5060031610643303, 0.5035797961792172, 0.5057599959860736, 0.5070494472392413, 0.5068886981024119, 0.5080855346713675, 0.505825812747342, 0.503375166915238, 0.5035259799879082]\n",
      "The n_neighbors with the highest knn_score is 9\n"
     ]
    }
   ],
   "source": [
    "# Search the best n_neighbors value to choose from 1 to 10\n",
    "n_neighbors = []\n",
    "knn_score_list = []\n",
    "for n in range(1,20):\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn = knn.score(X_test, y_test)\n",
    "    knn_score_list.append(knn)  \n",
    "    n_neighbors.append(n) \n",
    "print(knn_score_list)\n",
    "n_neighbors\n",
    "# find the index of the highest value\n",
    "max_index = np.argmax(knn_score_list)\n",
    "# get the corresponding label\n",
    "max_label = n_neighbors[max_index]\n",
    "print(f\"The n_neighbors with the highest knn_score is {max_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5088119804488029"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=max_label)\n",
    "knn = KNeighborsRegressor(n_neighbors=max_label)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn.predict([[3,2,1000,11000,2,1,\n",
    "#               1,1,1,750,0,900,\n",
    "#               9000,20,10]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A cause du danger du **`dataleaking`**\n",
    "Sur le jeu de train, on veut créer les transformateurs, par exemple le min-max scaler permet de transformer toutes les données entre 0 et 1 en soustrayant par le minimum et en divisant par le maximum. Cependant ces deux valeurs sont celles du jeu de train, pas celles du jeu en entier, car on n’a pas le droit de se servir des données du test (data-leaking). Il faut donc:\n",
    "- fit sur les valeurs trains et transform (d’ou fit-transform)\n",
    "- uniquement faire transform sur les valeurs du test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758173915957799"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df_new['price']\n",
    "X = df_new[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'sqft_living15','sqft_lot15', 'age_house']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,random_state=42)\n",
    "\n",
    "# pre-processing de X_train\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "X_train_min_max = minmax.fit_transform(X_train)\n",
    "\n",
    "# Entrainement sur X_train\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=max_label)\n",
    "trained_model = model.fit(X_train_min_max,y_train)\n",
    "\n",
    "# pre-processing de X_test\n",
    "X_test_min_max = minmax.transform(X_test)\n",
    "\n",
    "# scoring\n",
    "trained_model.score(X_test_min_max,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En programmation, on aime bien factoriser alors on va créer un pipeline. \n",
    "On liste les étapes en leur donnannt à chaque fois un nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df_new['price']\n",
    "X = df_new[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'sqft_living15','sqft_lot15', 'age_house']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#simple = SimpleImputer(strategy='mean')   # replaces missing data by the mean\n",
    "minmax = MinMaxScaler()\n",
    "knn_4 = KNeighborsRegressor(n_neighbors=max_label)\n",
    "\n",
    "pipe = Pipeline([\n",
    "     #('simple_imputer', simple ),\n",
    "     ('minmax', minmax),\n",
    "     ('knn', knn_4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758173915957799"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# y = df_new['price']\n",
    "# X = X\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# # On cree un pipeline de proprocessing pour les variables numériques\n",
    "# numeric_features = X\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# numeric_transformer = Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy='mean')),\n",
    "#         ('min_max', MinMaxScaler()),  # moyenne nulle et écart type = 1 -> Reg, SVM, PCA\n",
    "#         ])\n",
    "\n",
    "# # # On cree un pre-processeur pour les variables catégorielles\n",
    "# # categorial_features = [ \"zipcode\"]\n",
    "\n",
    "# # from sklearn.preprocessing import OneHotEncoder\n",
    "# # categorical_transformer = OneHotEncoder(sparse=True)\n",
    "\n",
    "\n",
    "# # a l'aide de la classe ColumnTransformer, \n",
    "# # on déclare à quelles variables on applique quel transformer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         # ('cat', categorical_transformer, categorial_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# #On obtient un pipeline de preprocessing qu'on peut utiliser dans un pipeline d'entainement\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# knn_4 = KNeighborsRegressor(n_neighbors=max_label)\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#      ('prep', preprocessor),\n",
    "#      ('knn', knn_4)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Entrainement sur X_train\n",
    "# trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# # prediction sur X_test\n",
    "# trained_pipe.predict(X_test)\n",
    "\n",
    "# # scoring sur X_test\n",
    "# trained_pipe.score(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor to cleaned df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>540088.14</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2079.90</td>\n",
       "      <td>15106.97</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1788.39</td>\n",
       "      <td>291.51</td>\n",
       "      <td>1971.01</td>\n",
       "      <td>84.40</td>\n",
       "      <td>98077.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>-122.21</td>\n",
       "      <td>1986.55</td>\n",
       "      <td>12768.46</td>\n",
       "      <td>2014.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>367127.20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>918.44</td>\n",
       "      <td>41420.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.18</td>\n",
       "      <td>828.09</td>\n",
       "      <td>442.58</td>\n",
       "      <td>29.37</td>\n",
       "      <td>401.68</td>\n",
       "      <td>53.51</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>685.39</td>\n",
       "      <td>27304.18</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>520.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98001.00</td>\n",
       "      <td>47.16</td>\n",
       "      <td>-122.52</td>\n",
       "      <td>399.00</td>\n",
       "      <td>651.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>321950.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1427.00</td>\n",
       "      <td>5040.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1190.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1951.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98033.00</td>\n",
       "      <td>47.47</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>5100.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>450000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1910.00</td>\n",
       "      <td>7618.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1560.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1975.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98065.00</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>7620.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>645000.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550.00</td>\n",
       "      <td>10688.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2210.00</td>\n",
       "      <td>560.00</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98118.00</td>\n",
       "      <td>47.68</td>\n",
       "      <td>-122.12</td>\n",
       "      <td>2360.00</td>\n",
       "      <td>10083.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7700000.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>13540.00</td>\n",
       "      <td>1651359.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9410.00</td>\n",
       "      <td>4820.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>98199.00</td>\n",
       "      <td>47.78</td>\n",
       "      <td>-121.31</td>\n",
       "      <td>6210.00</td>\n",
       "      <td>871200.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living   sqft_lot   floors  \\\n",
       "count   21613.00  21613.00   21613.00     21613.00   21613.00 21613.00   \n",
       "mean   540088.14      3.37       2.11      2079.90   15106.97     1.49   \n",
       "std    367127.20      0.93       0.77       918.44   41420.51     0.54   \n",
       "min     75000.00      0.00       0.00       290.00     520.00     1.00   \n",
       "25%    321950.00      3.00       1.75      1427.00    5040.00     1.00   \n",
       "50%    450000.00      3.00       2.25      1910.00    7618.00     1.50   \n",
       "75%    645000.00      4.00       2.50      2550.00   10688.00     2.00   \n",
       "max   7700000.00     33.00       8.00     13540.00 1651359.00     3.50   \n",
       "\n",
       "       waterfront     view  condition    grade  sqft_above  sqft_basement  \\\n",
       "count    21613.00 21613.00   21613.00 21613.00    21613.00       21613.00   \n",
       "mean         0.01     0.23       3.41     7.66     1788.39         291.51   \n",
       "std          0.09     0.77       0.65     1.18      828.09         442.58   \n",
       "min          0.00     0.00       1.00     1.00      290.00           0.00   \n",
       "25%          0.00     0.00       3.00     7.00     1190.00           0.00   \n",
       "50%          0.00     0.00       3.00     7.00     1560.00           0.00   \n",
       "75%          0.00     0.00       4.00     8.00     2210.00         560.00   \n",
       "max          1.00     4.00       5.00    13.00     9410.00        4820.00   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "count  21613.00      21613.00 21613.00 21613.00 21613.00       21613.00   \n",
       "mean    1971.01         84.40 98077.94    47.56  -122.21        1986.55   \n",
       "std       29.37        401.68    53.51     0.14     0.14         685.39   \n",
       "min     1900.00          0.00 98001.00    47.16  -122.52         399.00   \n",
       "25%     1951.00          0.00 98033.00    47.47  -122.33        1490.00   \n",
       "50%     1975.00          0.00 98065.00    47.57  -122.23        1840.00   \n",
       "75%     1997.00          0.00 98118.00    47.68  -122.12        2360.00   \n",
       "max     2015.00       2015.00 98199.00    47.78  -121.31        6210.00   \n",
       "\n",
       "       sqft_lot15     year  \n",
       "count    21613.00 21613.00  \n",
       "mean     12768.46  2014.32  \n",
       "std      27304.18     0.47  \n",
       "min        651.00  2014.00  \n",
       "25%       5100.00  2014.00  \n",
       "50%       7620.00  2014.00  \n",
       "75%      10083.00  2015.00  \n",
       "max     871200.00  2015.00  "
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>done_reno</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>age_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>...</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "      <td>21436.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4580765328.18</td>\n",
       "      <td>541649.96</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2082.70</td>\n",
       "      <td>15135.64</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.41</td>\n",
       "      <td>...</td>\n",
       "      <td>1971.10</td>\n",
       "      <td>84.73</td>\n",
       "      <td>98077.86</td>\n",
       "      <td>47.56</td>\n",
       "      <td>-122.21</td>\n",
       "      <td>1988.31</td>\n",
       "      <td>12785.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2014.33</td>\n",
       "      <td>43.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2876589633.67</td>\n",
       "      <td>367314.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "      <td>919.15</td>\n",
       "      <td>41538.62</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>29.39</td>\n",
       "      <td>402.43</td>\n",
       "      <td>53.47</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>685.70</td>\n",
       "      <td>27375.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>29.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000102.00</td>\n",
       "      <td>75000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>520.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98001.00</td>\n",
       "      <td>47.16</td>\n",
       "      <td>-122.52</td>\n",
       "      <td>399.00</td>\n",
       "      <td>651.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2123700078.75</td>\n",
       "      <td>324866.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1430.00</td>\n",
       "      <td>5040.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1952.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98033.00</td>\n",
       "      <td>47.47</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>5100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3904921185.00</td>\n",
       "      <td>450000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1920.00</td>\n",
       "      <td>7614.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1975.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98065.00</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>7620.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7308675062.50</td>\n",
       "      <td>645000.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550.00</td>\n",
       "      <td>10696.25</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98117.00</td>\n",
       "      <td>47.68</td>\n",
       "      <td>-122.12</td>\n",
       "      <td>2370.00</td>\n",
       "      <td>10087.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9900000190.00</td>\n",
       "      <td>7700000.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>13540.00</td>\n",
       "      <td>1651359.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>98199.00</td>\n",
       "      <td>47.78</td>\n",
       "      <td>-121.31</td>\n",
       "      <td>6210.00</td>\n",
       "      <td>871200.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      price  bedrooms  bathrooms  sqft_living   sqft_lot  \\\n",
       "count      21436.00   21436.00  21436.00   21436.00     21436.00   21436.00   \n",
       "mean  4580765328.18  541649.96      3.37       2.12      2082.70   15135.64   \n",
       "std   2876589633.67  367314.93      0.91       0.77       919.15   41538.62   \n",
       "min      1000102.00   75000.00      0.00       0.00       290.00     520.00   \n",
       "25%   2123700078.75  324866.00      3.00       1.75      1430.00    5040.00   \n",
       "50%   3904921185.00  450000.00      3.00       2.25      1920.00    7614.00   \n",
       "75%   7308675062.50  645000.00      4.00       2.50      2550.00   10696.25   \n",
       "max   9900000190.00 7700000.00     11.00       8.00     13540.00 1651359.00   \n",
       "\n",
       "        floors  waterfront     view  condition  ...  yr_built  yr_renovated  \\\n",
       "count 21436.00    21436.00 21436.00   21436.00  ...  21436.00      21436.00   \n",
       "mean      1.50        0.01     0.24       3.41  ...   1971.10         84.73   \n",
       "std       0.54        0.09     0.77       0.65  ...     29.39        402.43   \n",
       "min       1.00        0.00     0.00       1.00  ...   1900.00          0.00   \n",
       "25%       1.00        0.00     0.00       3.00  ...   1952.00          0.00   \n",
       "50%       1.50        0.00     0.00       3.00  ...   1975.00          0.00   \n",
       "75%       2.00        0.00     0.00       4.00  ...   1997.00          0.00   \n",
       "max       3.50        1.00     4.00       5.00  ...   2015.00       2015.00   \n",
       "\n",
       "       zipcode      lat     long  sqft_living15  sqft_lot15  done_reno  \\\n",
       "count 21436.00 21436.00 21436.00       21436.00    21436.00   21436.00   \n",
       "mean  98077.86    47.56  -122.21        1988.31    12785.96       0.04   \n",
       "std      53.47     0.14     0.14         685.70    27375.47       0.20   \n",
       "min   98001.00    47.16  -122.52         399.00      651.00       0.00   \n",
       "25%   98033.00    47.47  -122.33        1490.00     5100.00       0.00   \n",
       "50%   98065.00    47.57  -122.23        1840.00     7620.00       0.00   \n",
       "75%   98117.00    47.68  -122.12        2370.00    10087.25       0.00   \n",
       "max   98199.00    47.78  -121.31        6210.00   871200.00       1.00   \n",
       "\n",
       "       year_sold  age_house  \n",
       "count   21436.00   21436.00  \n",
       "mean     2014.33      43.23  \n",
       "std         0.47      29.39  \n",
       "min      2014.00      -1.00  \n",
       "25%      2014.00      17.00  \n",
       "50%      2014.00      39.00  \n",
       "75%      2015.00      63.00  \n",
       "max      2015.00     115.00  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['year'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[825], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m y \u001b[39m=\u001b[39m df_2[\u001b[39m'\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m X \u001b[39m=\u001b[39m df_2[[\u001b[39m'\u001b[39;49m\u001b[39mbedrooms\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbathrooms\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msqft_living\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msqft_lot\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mfloors\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mwaterfront\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mview\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcondition\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgrade\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msqft_above\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39msqft_basement\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39myr_built\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39myr_renovated\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mzipcode\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlat\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlong\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39msqft_living15\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msqft_lot15\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, train_size\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Création du pipeline\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['year'] not in index\""
     ]
    }
   ],
   "source": [
    "# Initialisation Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df_2['price']\n",
    "X = df_2[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors','waterfront', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'year']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#simple = SimpleImputer(strategy='mean')   # replaces missing data by the mean\n",
    "minmax = MinMaxScaler()\n",
    "knn = KNeighborsRegressor(n_neighbors=max_label)\n",
    "\n",
    "pipe = Pipeline([\n",
    "     #('simple_imputer', simple ),\n",
    "     ('minmax', minmax),\n",
    "     ('knn', knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750602801367432"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression Model to df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df['price']\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors','waterfront', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'year']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# simple = SimpleImputer(strategy='mean')   # replaces missing data by the mean\n",
    "minmax = MinMaxScaler()\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "     # ('simple_imputer', simple ),\n",
    "     ('minmax', minmax),\n",
    "     ('linear_model', linear_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026873921712173"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression Model to cleaned df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df_new['price']\n",
    "X = df_new[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','floors', 'view', 'condition', 'grade', 'sqft_above','sqft_basement', 'sqft_living15','sqft_lot15', 'age_house']]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# simple = SimpleImputer(strategy='mean')   # replaces missing data by the mean\n",
    "minmax = MinMaxScaler()\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "     # ('simple_imputer', simple ),\n",
    "     ('minmax', minmax),\n",
    "     ('linear_model', linear_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631824135180497"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-33 {color: black;background-color: white;}#sk-container-id-33 pre{padding: 0;}#sk-container-id-33 div.sk-toggleable {background-color: white;}#sk-container-id-33 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-33 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-33 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-33 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-33 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-33 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-33 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-33 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-33 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-33 div.sk-item {position: relative;z-index: 1;}#sk-container-id-33 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-33 div.sk-item::before, #sk-container-id-33 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-33 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-33 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-33 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-33 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-33 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-33 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-33 div.sk-label-container {text-align: center;}#sk-container-id-33 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-33 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Linear Model\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_std, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -504307.1597974545\n",
      "Columns: Index(['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'view',\n",
      "       'condition', 'grade', 'sqft_above', 'sqft_basement', 'sqft_living15',\n",
      "       'sqft_lot15', 'age_house'],\n",
      "      dtype='object')\n",
      "Coefficients: [-427207.56919602  309472.13245245  589007.41761978    2151.30697192\n",
      "   80903.65909751  283406.09010705   78589.35802974 1239267.2261669\n",
      "  479182.27211972  257530.80199885  184998.70846354 -456867.75952943\n",
      "  413794.72514   ]\n"
     ]
    }
   ],
   "source": [
    "print('Intercept: {}'.format(linear_model.intercept_))\n",
    "print('Columns: {}'.format(X_train.columns))\n",
    "print('Coefficients: {}'.format(linear_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6421423024328894"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the coefficient of determination R^2 of the prediction.\n",
    "linear_score = linear_model.score(X_train_std, y_train)\n",
    "linear_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apprenant/miniconda3/envs/machine_learning/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the scaled test data to generate the prediction price\n",
    "y_pred_linear = linear_model.predict(X_test_std_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46466671143.11312"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate the mean-squared error\n",
    "linear_mse = metrics.mean_squared_error(y_test, y_pred_linear)\n",
    "linear_mse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apprenant/miniconda3/envs/machine_learning/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just want to demostrate the answer will be one because the output is generated by the model\n",
    "linear_model.score(X_test_std_df_new, y_pred_linear) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model.predict([[3,2,1000,11000,2,1,\n",
    "#               1,1,1,750,0,900,\n",
    "#               9000,20,10,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>price</th>\n",
       "      <th>linear_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19847</td>\n",
       "      <td>384000.00</td>\n",
       "      <td>346734.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16533</td>\n",
       "      <td>234950.00</td>\n",
       "      <td>239467.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554</td>\n",
       "      <td>331500.00</td>\n",
       "      <td>342147.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14297</td>\n",
       "      <td>438000.00</td>\n",
       "      <td>368230.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6151</td>\n",
       "      <td>287000.00</td>\n",
       "      <td>389391.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16950</td>\n",
       "      <td>889000.00</td>\n",
       "      <td>939132.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16091</td>\n",
       "      <td>400000.00</td>\n",
       "      <td>496403.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15967</td>\n",
       "      <td>370000.00</td>\n",
       "      <td>262136.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5996</td>\n",
       "      <td>295000.00</td>\n",
       "      <td>540888.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16221</td>\n",
       "      <td>400000.00</td>\n",
       "      <td>472104.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7729</td>\n",
       "      <td>700000.00</td>\n",
       "      <td>716517.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13112</td>\n",
       "      <td>602000.00</td>\n",
       "      <td>430270.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10192</td>\n",
       "      <td>488500.00</td>\n",
       "      <td>370321.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6977</td>\n",
       "      <td>190000.00</td>\n",
       "      <td>302613.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12586</td>\n",
       "      <td>545000.00</td>\n",
       "      <td>510592.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15858</td>\n",
       "      <td>532000.00</td>\n",
       "      <td>339889.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16854</td>\n",
       "      <td>173250.00</td>\n",
       "      <td>361735.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7335</td>\n",
       "      <td>311000.00</td>\n",
       "      <td>668607.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2425</td>\n",
       "      <td>355000.00</td>\n",
       "      <td>224403.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8753</td>\n",
       "      <td>1010000.00</td>\n",
       "      <td>705064.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19179</td>\n",
       "      <td>660000.00</td>\n",
       "      <td>721764.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21221</td>\n",
       "      <td>389990.00</td>\n",
       "      <td>453650.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14165</td>\n",
       "      <td>848000.00</td>\n",
       "      <td>888131.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15750</td>\n",
       "      <td>275000.00</td>\n",
       "      <td>204200.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10597</td>\n",
       "      <td>415250.00</td>\n",
       "      <td>386658.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12759</td>\n",
       "      <td>340000.00</td>\n",
       "      <td>529654.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5503</td>\n",
       "      <td>227000.00</td>\n",
       "      <td>357012.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19668</td>\n",
       "      <td>435000.00</td>\n",
       "      <td>712995.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3710</td>\n",
       "      <td>778000.00</td>\n",
       "      <td>762134.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17180</td>\n",
       "      <td>335000.00</td>\n",
       "      <td>510234.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5216</td>\n",
       "      <td>440000.00</td>\n",
       "      <td>510876.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11498</td>\n",
       "      <td>519000.00</td>\n",
       "      <td>430940.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20561</td>\n",
       "      <td>790000.00</td>\n",
       "      <td>748379.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19954</td>\n",
       "      <td>1575000.00</td>\n",
       "      <td>682792.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2214</td>\n",
       "      <td>608000.00</td>\n",
       "      <td>566984.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8129</td>\n",
       "      <td>300000.00</td>\n",
       "      <td>337238.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10199</td>\n",
       "      <td>335620.00</td>\n",
       "      <td>471815.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4504</td>\n",
       "      <td>530000.00</td>\n",
       "      <td>576529.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7590</td>\n",
       "      <td>960000.00</td>\n",
       "      <td>780761.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4393</td>\n",
       "      <td>610000.00</td>\n",
       "      <td>586618.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4139</td>\n",
       "      <td>790000.00</td>\n",
       "      <td>493733.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15744</td>\n",
       "      <td>339300.00</td>\n",
       "      <td>280597.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4770</td>\n",
       "      <td>2479000.00</td>\n",
       "      <td>2090252.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6366</td>\n",
       "      <td>645000.00</td>\n",
       "      <td>574915.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21328</td>\n",
       "      <td>462500.00</td>\n",
       "      <td>270817.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3352</td>\n",
       "      <td>783350.00</td>\n",
       "      <td>965225.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20732</td>\n",
       "      <td>630000.00</td>\n",
       "      <td>448029.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>11741</td>\n",
       "      <td>425000.00</td>\n",
       "      <td>390256.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3492</td>\n",
       "      <td>525000.00</td>\n",
       "      <td>525455.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>15701</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>363082.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4140</td>\n",
       "      <td>360000.00</td>\n",
       "      <td>640592.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>20486</td>\n",
       "      <td>795000.00</td>\n",
       "      <td>814622.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5711</td>\n",
       "      <td>705000.00</td>\n",
       "      <td>790776.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3638</td>\n",
       "      <td>158000.00</td>\n",
       "      <td>364196.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10265</td>\n",
       "      <td>590000.00</td>\n",
       "      <td>420953.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2754</td>\n",
       "      <td>665000.00</td>\n",
       "      <td>711090.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6659</td>\n",
       "      <td>712000.00</td>\n",
       "      <td>576298.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3784</td>\n",
       "      <td>475000.00</td>\n",
       "      <td>403516.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2168</td>\n",
       "      <td>360000.00</td>\n",
       "      <td>340019.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9955</td>\n",
       "      <td>665000.00</td>\n",
       "      <td>906029.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      price  linear_pred\n",
       "0   19847  384000.00    346734.96\n",
       "1   16533  234950.00    239467.14\n",
       "2     554  331500.00    342147.49\n",
       "3   14297  438000.00    368230.49\n",
       "4    6151  287000.00    389391.74\n",
       "5   16950  889000.00    939132.84\n",
       "6   16091  400000.00    496403.12\n",
       "7   15967  370000.00    262136.58\n",
       "8    5996  295000.00    540888.48\n",
       "9   16221  400000.00    472104.55\n",
       "10   7729  700000.00    716517.86\n",
       "11  13112  602000.00    430270.82\n",
       "12  10192  488500.00    370321.48\n",
       "13   6977  190000.00    302613.17\n",
       "14  12586  545000.00    510592.25\n",
       "15  15858  532000.00    339889.48\n",
       "16  16854  173250.00    361735.46\n",
       "17   7335  311000.00    668607.01\n",
       "18   2425  355000.00    224403.27\n",
       "19   8753 1010000.00    705064.42\n",
       "20  19179  660000.00    721764.61\n",
       "21  21221  389990.00    453650.72\n",
       "22  14165  848000.00    888131.60\n",
       "23  15750  275000.00    204200.50\n",
       "24  10597  415250.00    386658.27\n",
       "25  12759  340000.00    529654.37\n",
       "26   5503  227000.00    357012.33\n",
       "27  19668  435000.00    712995.30\n",
       "28   3710  778000.00    762134.15\n",
       "29  17180  335000.00    510234.07\n",
       "30   5216  440000.00    510876.74\n",
       "31  11498  519000.00    430940.37\n",
       "32  20561  790000.00    748379.51\n",
       "33  19954 1575000.00    682792.53\n",
       "34   2214  608000.00    566984.28\n",
       "35   8129  300000.00    337238.15\n",
       "36  10199  335620.00    471815.37\n",
       "37   4504  530000.00    576529.73\n",
       "38   7590  960000.00    780761.77\n",
       "39   4393  610000.00    586618.63\n",
       "40   4139  790000.00    493733.37\n",
       "41  15744  339300.00    280597.12\n",
       "42   4770 2479000.00   2090252.55\n",
       "43   6366  645000.00    574915.37\n",
       "44  21328  462500.00    270817.97\n",
       "45   3352  783350.00    965225.78\n",
       "46  20732  630000.00    448029.69\n",
       "47  11741  425000.00    390256.83\n",
       "48   3492  525000.00    525455.88\n",
       "49  15701  395000.00    363082.02\n",
       "50   4140  360000.00    640592.91\n",
       "51  20486  795000.00    814622.66\n",
       "52   5711  705000.00    790776.38\n",
       "53   3638  158000.00    364196.78\n",
       "54  10265  590000.00    420953.22\n",
       "55   2754  665000.00    711090.29\n",
       "56   6659  712000.00    576298.49\n",
       "57   3784  475000.00    403516.71\n",
       "58   2168  360000.00    340019.66\n",
       "59   9955  665000.00    906029.02"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "n_rows = 60\n",
    "y_pred_linear_df_new = pd.DataFrame(y_pred_linear, columns = ['linear_pred']) \n",
    "model_results = pd.concat([y_test.reset_index(), y_pred_linear_df_new], axis = 1, sort = False) \n",
    "model_results.head(n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results[['price', 'linear_pred']].head(n_rows).plot.bar(figsize = (15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6421423024328894"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling\n",
    "# Since the features are in different scale, we want to scale the features before we train the model.\n",
    "# Create the Scaler object\n",
    "std_scaler = preprocessing.MinMaxScaler()\n",
    "# apply the transformation to the training data\n",
    "X_train_std = std_scaler.fit_transform(X_train) \n",
    "# apply the transformation to the testing data\n",
    "X_test_std = std_scaler.transform(X_test) # but we only transform our testing data with already fit scaler\n",
    "# convert resulting array back to dataframe\n",
    "X_test_std_df_new = pd.DataFrame(X_test_std, columns = X_train.columns)\n",
    "X_test_std_df_new.head()\n",
    "#-------------------------------------\n",
    "# Simple Linear Model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_std, y_train)\n",
    "# -----------------------------------\n",
    "# Return the coefficient of determination R^2 of the prediction.\n",
    "linear_score = linear_model.score(X_train_std, y_train)\n",
    "linear_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631824135180497"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline\n",
    "# Création du pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# simple = SimpleImputer(strategy='mean')   # replaces missing data by the mean\n",
    "minmax = MinMaxScaler()\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "     # ('simple_imputer', simple ),\n",
    "     ('minmax', minmax),\n",
    "     ('linear_model', linear_model)\n",
    "])\n",
    "\n",
    "\n",
    "# Entrainement sur X_train\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# prediction sur X_test\n",
    "trained_pipe.predict(X_test)\n",
    "\n",
    "# scoring sur X_test\n",
    "trained_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6372ac1f96e6a574de8fb7db2482e4b51a9c7365ff441969ce58324c2dcfaf16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
